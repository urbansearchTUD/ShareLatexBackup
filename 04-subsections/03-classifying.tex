\subsection{Extracting Relations from Documents}
Now that a selection of relevant documents has been made, we can make an attempt to identify the relations between cities based on these documents. Since labelling every relevant document by hand is not feasible an automated approach is desirable. 
One way to automate this process is by identifying intercity relations using machine learning. Machine learning algorithms can be roughly divided into two distinct groups: Supervised and unsupervised algorithms. Supervised algorithms expect an input set and a corresponding output set by which an model is trained to predict unseen instances of the problem. Unsupervised algorithms identify clusters of entities based on similarities in the feature set corresponding to said entity.
Considering the fact that we have a strict time schedule of only two months to develop the complete system, we decided with our client to go with the supervised approach. 
The main reason for this choice is that the training and tweaking of supervised algorithms can be done faster compared to unsupervised algorithms. The main reason for this is that we do not need the complete data-set to start training a supervised model, while for the unsupervised case the complete set is needed.

\subsubsection{Defining Classes}
Our choice of using classification has naturally lead to the need for categories we want to identify within the collected documents. Together with our clients, Dr. Evert Meijers and Antoine Peris, we identified the following categories which are useful to identify from the collected documents:\\

\begin{enumerate}
    \item Commuting
    \item Leisure
    \item Residential mobility
    \item Education
    \item Collaboration
    \item Transportation
    \item Other
\end{enumerate}

These categories represent topics that are of interest for our clients. They relate to research that is being done by our clients and to relations that were deemed important in previous research on intercity relations.

\subsubsection{Pre-processing}

For text pre-processing there are a number of tools available. We used NLTK \cite{3} removing stopwords and Scikit-Learn \cite{scikit-learn} for Modelling.
\begin{enumerate}
\item Tokenization. \\ splitting up the text into words and other symbols called tokens. For this we implemented the tokenizer NLTK provides. Testing showed that it does what it is supposed to do.
\item Removing stop words. \\ Removing all common words (the, a, an etc) and symbols ('.', ',', '!', etc). For removing stopwords we used a list from NLTK containing dutch stopwords. For removing symbols we made a method that removes all non alphabet values except spaces from text. 
\item Stemming. \\ Reducing derived words to their stem (e.g. fishing -> fish). We first wanted to use NLTK, which itself implements several stemmers including SnowBallStemmer \cite{snowball_dutch} and Porter \cite{porter_Stemmer}. However research from the Rijks Universiteit Groningen (RUG) by Tanja Gaustad and Gosse Bouma \cite{gaustad2002accurate} evaluated a Bayesian text classification system with either no stemming or the Porter or dictionary based stemmer. Which concluded stemming does not lead to significant change in classification accuracy.

\item Modelling (TF-IDF). \\ Before we can enter this tokenized data into the machine learning algorithm we first need to transform it to the correct model. Gensim provides two ready to use method for this to change tokenized text into the proper input data. The first is token2ID which gives each unique word a numeric ID and counts the amount that those words occur in a text and the second is tfidf which changes the amount that words occur in tf-idf values. tf-idf means term frequency inverse document frequency. Term frequency is the number of times the word occurs in a document and idf is the number of documents divided by the number of documents where the term occurs. These two values are then multiplied. The results are normalised to make up for different document lengths [https://radimrehurek.com/gensim/models/tfidfmodel.html].
\end{enumerate}

\subsubsection{training}
In order to use supervised machine learning, we first need to find training data for each class. We thought about two ways to do this. In order to get a good training sample for these categories, we discussed two different methods. \\

The first option was to query for results from news(paper) sites. However, this approach did not give us the desired results. The reason for this is that the categories we find in the newspapers do not match the categories Antoine and Evert provided us with. We also tried using the search engine from those news sites, however using those we found completely unrelated articles to the search queries (A search query about 'verhuizen' resulted in an article about parrots and minecraft).\\

The second option we are considering is to use Google Custom Search to obtain results from Google using the categories/keywords Antoine and Evert provided us with. A quick test with this last method provided us with quite good results (although we still see some noise in the results this is less than with the search engines from news sites).\\


\subsubsection{classifying}
For classifying there are a multitude of algorithms available. For choosing the classifier we make use of the Microsoft Azure Machine Learning Test Sheet \cite{MLCheatSheet}. Several factors should be taken into account when choosing an algorithm. These are:
    \begin{enumerate}
        \item Accuracy - How well the algorithm separates the websites.
        \item Training Time - How long it takes to train the algorithm.
        \item Linearity - Linear regression assumes data trends follow a straight line. This is trade-off between accuracy and speed.
        \item Number of Parameters - Adjustable parameters increase the flexibility of the algorithms. This is a trade-off between training time and accuracy.
        \item Number of Features - A large number of features can make some algorithms unfeasibly long. Especially text data (what we are using!) has a large number features. Support Vector Machines are especially well suited in this case.
        \item Special Cases - Some learning algorithms make particular assumptions about the data or the results.
    \end{enumerate}
    
    For textual data especially support vector machines are recommended, so it is most likely we will choose that machine learning algorithm. Depending on whether we have time we might do some tests before making our decision however. The sci-kit package\cite{scikit-learn} provides an easy to implement module to use this.


\begin{comment}
First, one or more subjects should be extracted from each relevant document. These subjects should reflect the contents of the document well in order to adequately identify relationships.
The second sub-task is to determine the relationships between the cities mentioned in the document, based on the extracted subjects.

% \\
% The first challenge we face is to extract one or more subjects from each document that we selected in the previous step. These subjects should be a good description of what is stated in the document and will be the main source of identifying the relations between the cities cited in the document.
% \\
% The second challenge is, using the former mentioned subjects, to identify relations based on these subjects. 
% \\
% We will consider several possibilities which can help us in tackling these challenges in the sections below.


\subsubsection{Extracting Subjects from Documents}
To identify the subjects associated with each individual document, we investigated several algorithms that we will present next.

\begin{description}
    \item[RAKE] offers an unsupervised, domain-independent, and language-independent method for extracting keywords from individual documents \cite{rose2010automatic}. This fits well within the context of our application. We work with individual documents which we want to label with one or more subjects/keywords.
    \item[Gensim]
    \item[NLTK]
\end{description}


\subsubsection{Identifying Relations Based on Subjects}


\end{comment}