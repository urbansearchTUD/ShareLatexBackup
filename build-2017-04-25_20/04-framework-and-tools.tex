\section{Frameworks and Tools}

\subsection{Extraction}
\subsubsection{Information Sources}

\paragraph{Common Crawl}
Common Crawl \cite{commoncrawl} is a freely accessible corpus of the web pages. Their data is updated and released on a monthly basis. They aim 

\paragraph{Eurostat}
% @Gijs: niet iets zeggen over wat het is?
We identified Eurostat as a source that is not useful for the problem we're going to solve. Although Eurostat contains a lot of statistics on European cities, there is not enough useful information which contributes to giving more insight into the network connectivity of cities. Therefore, we did not include Eurostat as an information source.
\subsubsection{methods}

\subsection{Filtering and Categorizing}

\subsubsection{Clustering}
\subsubsection{Filtering}
\subsubsection{Machine Learning}
\subsubsection{TF-IDF}
basic idea: 1. using training data to assign values on words - filter meaningless words - assign words with highest value as categories? 2. Do the same on training data for each category (choose a few documents manually per category) and then check for websites for which categories has the highest value.

\subsection{Search Queries}

\subsubsection{Enter Queries}
\subsubsection{Get Results}
\subsubsection{Specifications}

\subsection{Visualisation}
\subsubsection{neo4j?}

\subsubsection{Connection between cities}
\subsubsection{The Strength of these connections}