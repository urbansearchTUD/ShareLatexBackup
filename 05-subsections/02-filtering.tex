\section{Filtering the Data}\label{sec:5-filtering}
The next step in the process is filtering documents as explained in section \ref{sec:filtering_docs} and can be seen in figure \ref{fig:overview}. The implementation depends on the pyahocorasick library, which checks the page and tries to match strings within the page. We can supply this class with a list of cities which the Aho-Corasick algorithm will try to match. By default the application will retrieve a list of cities from the database and use this list to find matches in the text.

The implementation seemed straightforward at first, however, it became apparent that the algorithm matched sub-strings. For example, if a text contains "Leidende Amsterdammers" the Aho-Corasick algorithm would match because of the sub-strings "Amsterdam" and "Leiden". However, this should not be a match because "Leidende" is a verb. To solve this we added an additional check in the co-occurrence filtering which can be seen in listing \ref{lst:substring}. However, this might result in discarding documents that do contain interesting relations. However, this was the best way to get rid of a lot of false positives that we found within the short time span. 

\begin{lstlisting}[language=Python, caption=Additional check to prevent substring matches, label={lst:substring}]
for end, name in names:
    # Skip words that contain city names (e.g. Amsterdammers)
    if page[prev_end + 1] in 'abcdefghijklmnopqrstuvwxyz':
        prev_end, prev_name = end, name
\end{lstlisting}

Another problem that surfaced during the implementation of the co-occurrence check was the fact that Aho-Corasick is designed to be multi-matching. This means that it matches every occurrence of a city in the text, where we were interested which cities were found in the text but not if it was found multiple times. Therefore, the result of the Aho-Corasick algorithm was put into a set to solve this problem.
% ook ff zeggen dat we set moesten gebruiken omdat aho-corasick multimatch doet