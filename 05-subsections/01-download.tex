\section{Downloading and parsing indices}
As can be seen in figure \ref{fig:overview}, the first step of the process is to download data from Common Crawl. This required functions that would parse the Common Crawl indices and gather the data that corresponds to these indices. The first step in parsing the Common Crawl indices and filtering out the indices that have a HTTP Status Code \footnote{\url{https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html}} other than 200, as only these indices with these HTTP Status Code would be useful. 

At first a simple implementation was used as can be seen in listing x. However, a remove operation on a list in Python has a time complexity of O(n), the implementation of \textit{clean_indices()} loops over all indices and removes it if it has status other than 200, which meant that this function had a complexity of O(n^2). 
