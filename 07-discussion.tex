\chapter{Discussion}
% See http://libguides.usc.edu/writingguide/discussion for how to write a discussion

\todo{rephrase}
This section is divided into three parts. First we will discuss the influence of the research questions. Next we will mention issues we faced and which still remain. The last part of this section is dedicated to the ethical questions this project may involve.

\section{Discussing the research question answers something} \todo{better title}

\section{Issues Faced During Development}
\todo{THIS SECTION WILL BE REMOVED IN FAVOUR OF "Open Issues"}
\todo{check if everything is mentioned in ch5. if this is the case: discard this section, mention ch5 in Open Issues}
Over the course of the project, we came across multiple issues. 
\todo{memory problems}
    
\todo{multiprocessing}
\todo{text encoding}
\todo{python neo4j driver}


\section{Open Issues}\label{sec:Discussion - Open Issues}
Although we managed to handle most of the issues that arose during development, some remain unsolved. However, we believe that with more time, we could have found a solution to most issues. This is especially true for the classifier. Open issues with the classifier are therefore discussed separately, in section \ref{sec:discuss-classifier}.

\todo{subsection titles identical to those in ch5}
\subsection{Downloading and Parsing Indices}
The downloading part of the system is arguably the easiest of all. Indeed, the issues that remain are more related to the resources available, than to the implementation. Downloading speed is dependent on the connection to Common Crawl. Since their data is hosted at Amazon, it might be a lot faster to use a virtual private server of Amazon to host the system on, at least for data collection and storage. One is then able to use the Simple Storage Server (S3)\footnote{\url{https://aws.amazon.com/s3/}} to pull data more quickly from Common Crawl.

Another significant improvement is to use SSD instead of HDD storage, to speed up both reading and writing of files.

\subsection{Filtering the Data}
Filtering the downloaded documents went quite well overall, as explained in section \ref{sec:5-filtering}. However, we did leave out some important aspects. Most importantly, we had no means of checking on city aliases (like 's-Gravenhage is for Den Haag and Domstad for Utrecht). Additionally, we did not check whether 

\todo{Discuss choice to filter "Amsterdammers", future version might include this}
\todo{exporting data}
\todo{uneven amount of documents/class}
\todo{language}
\todo{processing time}
\todo{neo4j problems}
\todo{NoSQL vs SQL}
\todo{more....}

% describe issues faced during implementation, as well as issues that are still 
% open. Main thing here is to discuss the Neo4j python driver with multiprocessing,
% which we could not get to work. Also mention the state of the document 
% classification
\section{Classification} \label{sec:discuss-classifier}
% Describe issues faced during implementation/development
%Discuss open issues 

\section{Ethics}
In this section some of the ethical issues with respect to the developed product are discussed. First, possible issues with storing web data are discussed. Next, we discuss the potential consequences of extracted relations.
%Last, we will look at the environmental impact of running the application and storing the data.

\subsection{Storage of Data}
One of the ethical issues is the storage of web pages. Although these pages are accessible to anyone at the time of downloading, this might change in the future. The owner of the original web page may have good reason to delete the original page, however, this does not mean it is deleted from the local storage of our application. Another issue with storing the web pages locally is a potential violation of copyright. As Thelwall et al. stated, "web crawlers ostensibly do something illegal: They make permanent copies of copyright material (Web pages) without the ownerâ€™s permission."\cite{thelwall2006web} Because we store copies of the web data that has been crawled and stored by Common Crawl, the same applies to our application.

\subsection{Consequences of Extracted Relations}
Another issue is that it is unknown how the results of the application will be used. It was designed for research purposes, but there is no way of knowing what the results will be used for. For example, the extracted relationships show which cities are the most important in a network of cities. This information can be used by terrorists to decide to strike in the most important city to maximise the impact. 

The results may also result in some cities becoming more popular, which means they would grow in size. This might have a negative impact on for example the health and living conditions of the people in these cities.

%\subsection{Environmental Impact}
%To run the application and provide the required amount of storage the application will be deployed on one or multiple servers. These servers need to be powered and cooled which means that running the application to parse all the data will have a negative impact on the environment. The question is whether the benefits of having the results of the application outweigh the negative impact it might have on the environment.
