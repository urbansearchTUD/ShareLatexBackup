\chapter{Discussion}
% See http://libguides.usc.edu/writingguide/discussion for how to write a discussion

\todo{rephrase}
This section is divided into three parts. First we will discuss the influence of the research questions. Next we will mention issues we faced and which still remain. The last part of this section is dedicated to the ethical questions this project may involve.

\section{Discussing the research question answers something} \todo{better title}

\section{Issues Faced During Development}
\todo{memory problems}
    
\todo{multiprocessing}
\todo{text encoding}
\todo{python neo4j driver}


\section{Open Issues}\label{sec:Discussion - Open Issues}
\todo{Discuss choice to filter "Amsterdammers", future version might include this}
\todo{exporting data}
\todo{uneven amount of documents/class}
\todo{language}
\todo{processing time}
\todo{neo4j problems}
\todo{NoSQL vs SQL}
\todo{more....}

% describe issues faced during implementation, as well as issues that are still 
% open. Main thing here is to discuss the Neo4j python driver with multiprocessing,
% which we could not get to work. Also mention the state of the document 
% classification
\section{Classification}
% Describe issues faced during implementation/development
%Discuss open issues 

\section{Ethics}
In this section some of the ethical issues with respect to the developed product are discussed. First, possible issues with storing web data are discussed. Next, the potential consequences of extracted relations are discussed. Last, we will look at the environmental impact of running the application and storing the data.

\subsection{Storage of Data}
One of the ethical issues is the storage of web pages. Although these pages are accessible to anyone at the time of downloading, this might change in the future. The owner of the original web page may have good reason to delete the original page, however, this does not mean it is deleted from the local storage of our application. Another issue with storing the web pages locally is a potential violation of copyright. As Thelwall et al. stated, "web crawlers ostensibly do something illegal: They make permanent copies of copyright material (Web pages) without the ownerâ€™s permission."\cite{thelwall2006web} Because we store copies of the web data that has been crawled and stored by Common Crawl, the same applies to our application.

\subsection{Consequences of Extracted Relations}
Another issue is that it is unknown how the results of the application will be used. It was designed for research purposes, but there is no way of knowing what the results will be used for. For example, the extracted relationships show which cities are the most important in a network of cities. This information can be used by terrorists to decide to strike in the most important city to maximise the impact. 

The results may also result in some cities becoming more popular, which means they would grow in size. This might have a negative impact on for example the health and living conditions of the people in these cities.

\subsection{Environmental Impact}
To run the application and provide the required amount of storage the application will be deployed on one or multiple servers. These servers need to be powered and cooled which means that running the application to parse all the data will have a negative impact on the environment. The question is whether the benefits of having the results of the application outweigh the negative impact it might have on the environment.
